provider "aws" {
  region = "us-east-2"
}
# Make a kinesis data stream
resource "aws_kinesis_stream" "mta_stream" {
  name        = "mta-realtime-stream"
  shard_count = 1
  retention_period = 24
}

# Make a dynamoDB table for the trip update data
resource "aws_dynamodb_table" "pipeline_trips" {
  name           = "mta-pipeline-trips-table"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "event_id" # Generated by fetcher lambda function
  attribute {
    name = "event_id"
    type = "S"
  }
}

# Make a dynamoDB table for the service alerts data
resource "aws_dynamodb_table" "pipeline_alerts" {
  name           = "mta-pipeline-alerts-table"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "event_id" # Generated by fetcher lambda function
  attribute {
    name = "event_id"
    type = "S"
  }
}

# Make a dynamoDB table for the vehicle positions data
resource "aws_dynamodb_table" "pipeline_vehicles" {
  name           = "mta-pipeline-vehicle-table"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "trip_id" # Generated by fetcher lambda function
  range_key      = "position_timestamp"
  attribute {
    name = "trip_id"
    type = "S"
  }
  attribute {
    name = "position_timestamp"
    type = "N"
  }
}

# Make a dynamoDB table for the static schedule data

# DynamoDB table mapping stop_id to stop_name
resource "aws_dynamodb_table" "static_stops" {
  name           = "mta-static-stops-table"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "stop_id"

  attribute {
    name = "stop_id"
    type = "S"
  }
}

# DynamoDB table to store scheduled times
resource "aws_dynamodb_table" "static_stop_times" {
  name           = "mta-static-stop-times-table"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "trip_id"
  range_key      = "stop_sequence"

  attribute {
    name = "trip_id"
    type = "S"
  }
  attribute {
    name = "stop_sequence"
    type = "N"
  }
}

resource "aws_sns_topic" "mta_delay_alerts" {
  name = "mta_delay_alerts_topic"
}

# Make the fetcher lambda function
resource "aws_lambda_function" "fetcher" {
  function_name    = "mta-fetcher-function"
  role             = aws_iam_role.fetcher_role.arn
  handler          = "lambda_function.lambda_handler"
  runtime          = "python3.10"
  filename         = "../fetcher.zip" # Assumes zip file is in the root directory
  source_code_hash = filebase64sha256("../fetcher.zip")
  timeout          = 60
  layers = [
    "arn:aws:lambda:us-east-2:245902329972:layer:testingLayer:4"
  ]
  environment {
    variables = {
      KINESIS_STREAM_NAME = aws_kinesis_stream.mta_stream.name
    }
  }
}

# Make the rules engine lambda function
resource "aws_lambda_function" "rules_engine" {
  function_name    = "mta-rules-engine-function"
  role             = aws_iam_role.rules_engine_role.arn
  handler          = "lambda_function.lambda_handler"
  runtime          = "python3.10"
  filename         = "../rules_engine.zip"
  source_code_hash = filebase64sha256("../rules_engine.zip")
  timeout          = 30
  memory_size      = 512
  layers = [
    "arn:aws:lambda:us-east-2:245902329972:layer:testingLayer:4"
  ]
  environment {
    variables = {
      TRIPS_TABLE_NAME      = aws_dynamodb_table.pipeline_trips.name
      ALERTS_TABLE_NAME     = aws_dynamodb_table.pipeline_alerts.name
      VEHICLE_TABLE_NAME    = aws_dynamodb_table.pipeline_vehicles.name
      STOPS_TABLE_NAME      = aws_dynamodb_table.static_stops.name
      STOP_TIMES_TABLE_NAME = aws_dynamodb_table.static_stop_times.name
      SNS_TOPIC_ARN         = aws_sns_topic.mta_delay_alerts.arn
    }
  }
}

# Make roles for the different interactions

# Role for fetcher lambda
resource "aws_iam_role" "fetcher_role" {
  name = "mta-fetcher-lambda-role"
  assume_role_policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [{
      Action    = "sts:AssumeRole",
      Effect    = "Allow",
      Principal = { Service = "lambda.amazonaws.com" }
    }]
  })
}

# Permissions for the fetcher lambda (access to logs for debugging and writing to the kinesis data stream)
resource "aws_iam_role_policy" "fetcher_policy" {
  name = "mta-fetcher-policy"
  role = aws_iam_role.fetcher_role.id
  policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [
      {
        Effect   = "Allow",
        Action   = "logs:CreateLogGroup",
        Resource = "arn:aws:logs:us-east-2:245902329972:*"
      },
      {
        Effect   = "Allow",
        Action   = ["logs:CreateLogStream", "logs:PutLogEvents"],
        Resource = "arn:aws:logs:us-east-2:245902329972:log-group:/aws/lambda/mta-fetcher-function:*"
      },
      {
        Effect   = "Allow",
        Action   = "kinesis:PutRecords",
        Resource = aws_kinesis_stream.mta_stream.arn
      }
    ]
  })
}

# Role for the rules engine lambda
resource "aws_iam_role" "rules_engine_role" {
  name = "mta-rules-engine-lambda-role"
  assume_role_policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [{
      Action    = "sts:AssumeRole",
      Effect    = "Allow",
      Principal = { Service = "lambda.amazonaws.com" }
    }]
  })
}

# Permissions for the rules engine lambda (logs for debugging, reading kinesis data stream, writing to dynamoDB)
resource "aws_iam_role_policy" "rules_engine_policy" {
  name = "mta-rules-engine-policy"
  role = aws_iam_role.rules_engine_role.id
  policy = jsonencode({
    Version   = "2012-10-17",
    Statement =  [
      {
        Effect   = "Allow",
        Action   = "logs:CreateLogGroup",
        Resource = "arn:aws:logs:us-east-2:245902329972:*"
      },
      {
        Effect   = "Allow",
        Action   = ["logs:CreateLogStream", "logs:PutLogEvents"],
        Resource = "arn:aws:logs:us-east-2:245902329972:log-group:/aws/lambda/mta-rules-engine-function:*"
      },
      {
        Effect   = "Allow",
        Action   = ["kinesis:GetRecords", "kinesis:GetShardIterator", "kinesis:DescribeStream", "kinesis:ListShards"],
        Resource = aws_kinesis_stream.mta_stream.arn
      },
      {
        Effect   = "Allow",
        Action   = [
          "dynamodb:BatchWriteItem",
          "dynamodb:PutItem",
          "dynamodb:Query",
          "dynamodb:GetItem"
        ],
        Resource = [
          aws_dynamodb_table.pipeline_trips.arn,
          aws_dynamodb_table.pipeline_alerts.arn,
          aws_dynamodb_table.pipeline_vehicles.arn,
          aws_dynamodb_table.static_stops.arn,
          aws_dynamodb_table.static_stop_times.arn
        ]
      },
      {
        Effect   = "Allow",
        Action   = "lambda:InvokeFunction",
        Resource = aws_lambda_function.rules_engine.arn
      },
      {
        Effect   = "Allow"
        Action   = "sns:Publish"
        Resource = aws_sns_topic.mta_delay_alerts.arn
      }
    ]
  })
}

# Triggers and rules for interaction 

# EventBridge rule: trigger lambda function for each minute
resource "aws_cloudwatch_event_rule" "every_minute" {
  name                = "every-minute"
  schedule_expression = "rate(1 minute)"
}

# Connect the rule to the fetcher lambda
resource "aws_cloudwatch_event_target" "trigger_fetcher" {
  rule = aws_cloudwatch_event_rule.every_minute.name
  arn  = aws_lambda_function.fetcher.arn
}

# Give EventBridge permission to invoke the fetcher lambda
resource "aws_lambda_permission" "allow_cloudwatch" {
  statement_id  = "AllowExecutionFromCloudWatch"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.fetcher.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.every_minute.arn
}

# Connect the kinesis stream to trigger the rules engine lambda
resource "aws_lambda_event_source_mapping" "kinesis_trigger" {
  event_source_arn  = aws_kinesis_stream.mta_stream.arn
  function_name     = aws_lambda_function.rules_engine.arn
  starting_position = "LATEST"
  batch_size        = 100 # How many records to process at once
}

# Define the IAM Role and Policy for our new Dashboard Lambda
resource "aws_iam_role" "dashboard_lambda_role" {
  name = "mta-dashboard-lambda-role"
  assume_role_policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [{
      Action    = "sts:AssumeRole",
      Effect    = "Allow",
      Principal = { Service = "lambda.amazonaws.com" }
    }]
  })
}

resource "aws_iam_role_policy" "dashboard_lambda_policy" {
  name = "mta-dashboard-lambda-policy"
  role = aws_iam_role.dashboard_lambda_role.id
  policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [
      # Standard permissions for logging
      {
        Effect   = "Allow",
        Action   = "logs:CreateLogGroup",
        Resource = "arn:aws:logs:us-east-2:245902329972:*" # Use your region/account
      },
      {
        Effect   = "Allow",
        Action   = ["logs:CreateLogStream", "logs:PutLogEvents"],
        Resource = "arn:aws:logs:us-east-2:245902329972:log-group:/aws/lambda/mta-dashboard-function:*"
      },
      # CRITICAL: Permission to read from your main archive table
      {
        Effect   = "Allow",
        Action   = "dynamodb:Scan", # Scan is okay for this dashboard use case
        Resource = aws_dynamodb_table.pipeline_trips.arn
      }
    ]
  })
}

# Define the new Lambda function itself
resource "aws_lambda_function" "dashboard_lambda" {
  function_name    = "mta-dashboard-function"
  role             = aws_iam_role.dashboard_lambda_role.arn
  handler          = "lambda_function.lambda_handler"
  runtime          = "python3.10" # Match your other functions
  
  filename         = "../dashboard.zip"
  source_code_hash = filebase64sha256("../dashboard.zip")
  
  timeout          = 20
  memory_size      = 256

  layers = [ "arn:aws:lambda:us-east-2:245902329972:layer:testingLayer:4" ]
}

# Define the API Gateway and connect it to the Lambda
resource "aws_apigatewayv2_api" "mta_api" {
  name          = "mta-live-api"
  protocol_type = "HTTP"
}

resource "aws_apigatewayv2_integration" "dashboard_integration" {
  api_id           = aws_apigatewayv2_api.mta_api.id
  integration_type = "AWS_PROXY"
  integration_uri  = aws_lambda_function.dashboard_lambda.invoke_arn
}

resource "aws_apigatewayv2_route" "live_delays_route" {
  api_id    = aws_apigatewayv2_api.mta_api.id
  route_key = "GET /live-delays"
  target    = "integrations/${aws_apigatewayv2_integration.dashboard_integration.id}"
}

# API Gateway permission to invoke your Lambda function
resource "aws_lambda_permission" "api_gateway_permission" {
  statement_id  = "AllowAPIGatewayInvoke"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.dashboard_lambda.function_name
  principal     = "apigateway.amazonaws.com"

  # This is a bit complex, but it scopes the permission to your specific API route
  source_arn = "${aws_apigatewayv2_api.mta_api.execution_arn}/*/*"
}

# Create API Gateway Stage
resource "aws_apigatewayv2_stage" "default_stage" {
  api_id      = aws_apigatewayv2_api.mta_api.id
  name        = "$default"
  auto_deploy = true
}

# IAM Role and Policy for the Prediction Lambda
resource "aws_iam_role" "prediction_lambda_role" {
  name = "mta-prediction-lambda-role"
  assume_role_policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [{
      Action    = "sts:AssumeRole",
      Effect    = "Allow",
      Principal = { Service = "lambda.amazonaws.com" }
    }]
  })
}

resource "aws_iam_role_policy" "prediction_lambda_policy" {
  name = "mta-prediction-lambda-policy"
  role = aws_iam_role.prediction_lambda_role.id
  policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [
      {
        Effect   = "Allow",
        Action   = ["logs:CreateLogGroup", "logs:CreateLogStream", "logs:PutLogEvents"],
        Resource = "arn:aws:logs:us-east-2:245902329972:log-group:/aws/lambda/mta-prediction-function:*"
      },
      {
        Effect   = "Allow",
        Action   = "sagemaker:InvokeEndpoint",
        # Important: Scope this to your specific endpoint ARN for security
        Resource = "arn:aws:sagemaker:us-east-2:245902329972:endpoint/mta-travel-time-predictor"
      }
    ]
  })
}

# Make a prediction lambda function itself
resource "aws_lambda_function" "prediction_lambda" {
  function_name    = "mta-prediction-function"
  role             = aws_iam_role.prediction_lambda_role.arn
  handler          = "lambda_function.lambda_handler"
  runtime          = "python3.10"
  
  filename         = "../prediction.zip"
  source_code_hash = filebase64sha256("../prediction.zip")
  
  timeout          = 20
  memory_size      = 256
  
  environment {
    variables = {
      # Pass the name of the SageMaker endpoint to the Lambda
      SAGEMAKER_ENDPOINT_NAME = "mta-travel-time-predictor"
    }
  }
}

# Make API Gateway Route for predictions
resource "aws_apigatewayv2_route" "prediction_route" {
  api_id    = aws_apigatewayv2_api.mta_api.id
  route_key = "POST /predict-travel-time" # Using POST for requests with a body
  target    = "integrations/${aws_apigatewayv2_integration.prediction_integration.id}"
}

# The integration between the new route and the new Lambda
resource "aws_apigatewayv2_integration" "prediction_integration" {
  api_id           = aws_apigatewayv2_api.mta_api.id
  integration_type = "AWS_PROXY"
  integration_uri  = aws_lambda_function.prediction_lambda.invoke_arn
}

# API Gateway permission to invoke the lambda function
resource "aws_lambda_permission" "api_gateway_prediction_permission" {
  statement_id  = "AllowAPIGatewayInvokePrediction"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.prediction_lambda.function_name
  principal     = "apigateway.amazonaws.com"
  source_arn    = "${aws_apigatewayv2_api.mta_api.execution_arn}/*/*"
}
